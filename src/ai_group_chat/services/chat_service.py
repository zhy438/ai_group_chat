"""èŠå¤©æœåŠ¡ - ä¸šåŠ¡é€»è¾‘å±‚"""

import asyncio
import re
from collections import Counter
from pathlib import Path
import yaml
from loguru import logger
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.conditions import ExternalTermination

from ..models import (
    GroupChat, GroupChatCreate,
    AIMember, AIMemberCreate, AIMemberUpdate,
    Message, MessageRole, MessageType,
    DiscussionRequest, DiscussionResponse, SummarizeRequest,
    DiscussionMode,
)
from ..agents import AIGroupChat
from ..memory import ContextManager, LongTermMemoryService
from ..tools import GroupToolkitBundle, build_group_toolkits
from .chat_repository import ChatRepository

# å®¹é”™å¯¼å…¥é¢„è®¾æ•°æ®
try:
    from .presets import PRESET_GROUPS
except (ImportError, ModuleNotFoundError):
    PRESET_GROUPS = []


def _load_models_config() -> dict:
    """åŠ è½½æ¨¡å‹é…ç½®ï¼Œè¿”å› model_id -> context_window æ˜ å°„"""
    project_root = Path(__file__).parent.parent.parent.parent
    config_path = project_root / "config" / "models.yaml"
    
    if not config_path.exists():
        return {}
    
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        
        return {
            m["model_id"]: m.get("context_window", 128000)
            for m in config.get("models", [])
        }
    except Exception as e:
        logger.warning(f"åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        return {}


# å…¨å±€æ¨¡å‹é…ç½®ç¼“å­˜
_MODEL_CONTEXT_WINDOWS: dict = {}


class ChatService:
    """
    èŠå¤©æœåŠ¡
    
    ä¸šåŠ¡é€»è¾‘å±‚ï¼šè´Ÿè´£ç¼–æ’ä¸šåŠ¡æµç¨‹ã€è°ƒç”¨ Repository è¿›è¡Œæ•°æ®å­˜å–ã€‚
    ä¸åŒ…å«ä»»ä½• SQL è¯­å¥ã€‚
    """
    
    DEFAULT_CONTEXT_WINDOW = 128000  # é»˜è®¤ä¸Šä¸‹æ–‡çª—å£
    AUTO_INJECTION_MEMORY_TYPES = {"user_profile", "user_preference", "user_habit", "user_constraint"}
    AUTO_INJECTION_SCOPES = {"user_global"}
    
    def __init__(self):
        self.repo = ChatRepository()
        self.context_manager = ContextManager()  # ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.long_term_memory = LongTermMemoryService(self.repo)
        self._active_discussions: dict[str, ExternalTermination] = {}
        self._discussion_lock = asyncio.Lock()
        self._ensure_models_loaded()
        self._load_presets()
    
    def _ensure_models_loaded(self):
        """ç¡®ä¿æ¨¡å‹é…ç½®å·²åŠ è½½"""
        global _MODEL_CONTEXT_WINDOWS
        if not _MODEL_CONTEXT_WINDOWS:
            _MODEL_CONTEXT_WINDOWS = _load_models_config()
            logger.info(f"ğŸ“‹ å·²åŠ è½½ {len(_MODEL_CONTEXT_WINDOWS)} ä¸ªæ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£é…ç½®")
    
    def get_min_context_window(self, group: GroupChat) -> int:
        """
        è·å–ç¾¤èŠä¸­æ‰€æœ‰æ¨¡å‹çš„æœ€å°ä¸Šä¸‹æ–‡çª—å£
        
        Args:
            group: ç¾¤èŠå¯¹è±¡
            
        Returns:
            æœ€å°ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆtokensï¼‰
        """
        if not group.members:
            return self.DEFAULT_CONTEXT_WINDOW
        
        context_windows = []
        
        # æ”¶é›†æ‰€æœ‰æˆå‘˜æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£
        for member in group.members:
            model_id = member.model_id
            window = _MODEL_CONTEXT_WINDOWS.get(model_id, self.DEFAULT_CONTEXT_WINDOW)
            context_windows.append(window)
        
        # å¦‚æœæœ‰ manager æ¨¡å‹ï¼Œä¹Ÿè¦è€ƒè™‘
        if group.manager_model:
            manager_window = _MODEL_CONTEXT_WINDOWS.get(
                group.manager_model, self.DEFAULT_CONTEXT_WINDOW
            )
            context_windows.append(manager_window)
        
        min_window = min(context_windows) if context_windows else self.DEFAULT_CONTEXT_WINDOW
        logger.debug(f"ğŸ“ ç¾¤èŠ {group.name} æœ€å°ä¸Šä¸‹æ–‡çª—å£: {min_window} tokens")
        return min_window
    
    def _load_presets(self):
        """åŠ è½½é¢„è®¾æµ‹è¯•æ•°æ®"""
        if not PRESET_GROUPS:
            return
        
        for preset in PRESET_GROUPS:
            if self.repo.get_group_by_name(preset["name"]):
                continue

            # åˆ›å»ºç¾¤èŠ (Use repository)
            group = self.repo.create_group(
                name=preset["name"],
                manager_model=preset.get("manager_model", "gpt-4o-mini"),
                discussion_mode=DiscussionMode.FREE
            )
            
            # æ·»åŠ æˆå‘˜
            for member_data in preset["members"]:
                self.repo.add_raw_member(
                    group_id=group.id,
                    name=member_data["name"],
                    model_id=member_data["model_id"],
                    description=member_data.get("description"),
                    thinking=member_data.get("thinking", False),
                    temperature=member_data.get("temperature", 0.7)
                )
            
            logger.info(f"ğŸ“¦ åˆå§‹åŒ–é¢„è®¾ç¾¤èŠ: {preset['name']} ({len(preset['members'])} ä¸ªæˆå‘˜)")

    # ============ ç¾¤èŠç®¡ç† ============
    
    def create_group(self, data: GroupChatCreate) -> GroupChat:
        return self.repo.create_group(data.name)
    
    def get_group(self, group_id: str) -> GroupChat | None:
        return self.repo.get_group(group_id)
    
    def list_groups(self) -> list[GroupChat]:
        return self.repo.list_groups()
    
    def delete_group(self, group_id: str) -> bool:
        return self.repo.delete_group(group_id)
    
    # ============ æˆå‘˜ç®¡ç† ============
    
    def add_member(self, group_id: str, data: AIMemberCreate) -> AIMember | None:
        if not self.repo.get_group(group_id):
            return None
        return self.repo.add_member(group_id, data)
    
    def update_member(self, group_id: str, member_id: str, data: AIMemberUpdate) -> AIMember | None:
        return self.repo.update_member(group_id, member_id, data)
    
    def set_manager_config(self, group_id: str, model_id: str, thinking: bool = None, temperature: float = None) -> bool:
        if not self.repo.get_group(group_id):
            return False
        return self.repo.update_manager_config(group_id, model_id, thinking, temperature)

    async def update_compression_threshold(self, group_id: str, threshold: float) -> bool:
        """æ›´æ–°ç¾¤èŠå‹ç¼©é˜ˆå€¼ï¼Œå¹¶ç«‹å³è§¦å‘å‹ç¼©æ£€æŸ¥"""
        if not self.repo.get_group(group_id):
            return False
            
        # æ›´æ–°æ•°æ®åº“é…ç½®
        updated = self.repo.update_group_compression_threshold(group_id, threshold)
        if not updated:
            return False
            
        # ç«‹å³è§¦å‘ä¸€æ¬¡å‹ç¼©é€»è¾‘ä»¥åº”ç”¨æ–°é˜ˆå€¼
        try:
            await self._get_history_as_autogen_messages(group_id, limit=0)
        except Exception as e:
            logger.error(f"Error triggering immediate compression: {e}")
            # Do not fail request, user config is updated
            
        return True

    def update_memory_settings(self, group_id: str, settings: dict) -> bool:
        """æ›´æ–°ç¾¤èŠé•¿æœŸè®°å¿†é…ç½®"""
        if not self.repo.get_group(group_id):
            return False
        return self.repo.update_group_memory_settings(group_id, settings)

    def get_memory_stats(self, group_id: str) -> dict:
        """è·å–é•¿æœŸè®°å¿†ç»Ÿè®¡"""
        if not self.repo.get_group(group_id):
            raise ValueError("ç¾¤èŠä¸å­˜åœ¨")
        return self.long_term_memory.get_group_stats(group_id)

    def _build_toolkits(self, group: GroupChat, user_id: str) -> GroupToolkitBundle:
        """æ„å»ºç¾¤èŠå·¥å…·é›†ï¼šæˆå‘˜å…±äº«å·¥å…· + ç³»ç»ŸAgentä¸“å±å·¥å…·ã€‚"""
        try:
            return build_group_toolkits(
                group=group,
                user_id=user_id,
                memory_service=self.long_term_memory,
                max_context_tokens=self.get_min_context_window(group),
            )
        except Exception as e:
            logger.warning(f"æ„å»ºå·¥å…·é›†å¤±è´¥ï¼Œé™çº§ä¸ºæ— å·¥å…·æ¨¡å¼: {e}")
            return GroupToolkitBundle(member_tools=[], manager_tools=[])

    @staticmethod
    def _build_system_termination_notice(reason: str | None = None) -> str:
        """æ„é€ ç³»ç»ŸAgentæå‰ç»ˆæ­¢æç¤ºã€‚"""
        base = "ç³»ç»Ÿå·²åˆ¤æ–­å½“å‰è¯é¢˜å·²å®Œæˆï¼Œå·²ä¸»åŠ¨ç»ˆæ­¢æœ¬è½®è®¨è®ºã€‚"
        cleaned = (reason or "").strip()
        cleaned = re.sub(r"^å·²ç¡®è®¤æå‰ç»ˆæ­¢è®¨è®º[:ï¼š]?", "", cleaned).strip()
        if cleaned:
            return f"{base}ï¼ˆç»ˆæ­¢åŸå› ï¼š{cleaned}ï¼‰"
        return base

    @staticmethod
    def _build_manual_termination_notice() -> str:
        """æ„é€ æ‰‹åŠ¨ç»ˆæ­¢æç¤ºã€‚"""
        return "å·²æ‰‹åŠ¨ç»ˆæ­¢æœ¬è½®è®¨è®ºã€‚"

    async def _register_active_discussion(self, group_id: str, termination: ExternalTermination) -> None:
        """æ³¨å†Œå½“å‰ç¾¤èŠçš„æ´»è·ƒè®¨è®ºï¼›è‹¥å·²æœ‰è¿è¡Œä¸­çš„è®¨è®ºï¼Œå…ˆè¯·æ±‚å…¶åœæ­¢ã€‚"""
        async with self._discussion_lock:
            previous = self._active_discussions.get(group_id)
            if previous and previous is not termination:
                previous.set()
            self._active_discussions[group_id] = termination

    async def _clear_active_discussion(self, group_id: str, termination: ExternalTermination) -> None:
        """æ¸…ç†æ´»è·ƒè®¨è®ºæ³¨å†Œï¼ˆä»…æ¸…ç†å½“å‰å®ä¾‹ï¼‰ã€‚"""
        async with self._discussion_lock:
            current = self._active_discussions.get(group_id)
            if current is termination:
                self._active_discussions.pop(group_id, None)

    def stop_discussion(self, group_id: str) -> bool:
        """æ‰‹åŠ¨ç»ˆæ­¢ç¾¤èŠä¸­æ­£åœ¨è¿è¡Œçš„è®¨è®ºã€‚"""
        termination = self._active_discussions.get(group_id)
        if not termination:
            return False
        termination.set()
        return True

    async def _build_auto_injection_memory_block(self, group: GroupChat, user_id: str, query: str) -> str:
        """è‡ªåŠ¨æ³¨å…¥ä»…åŒ…å«ç”¨æˆ·åå¥½ï¼Œä¸æ³¨å…¥ç¾¤èŠç»“è®º/agentç”»åƒã€‚"""
        return await self.long_term_memory.build_injection_context(
            group=group,
            user_id=user_id,
            query=query,
            max_context_tokens=self.get_min_context_window(group),
            memory_types=self.AUTO_INJECTION_MEMORY_TYPES,
            scopes=self.AUTO_INJECTION_SCOPES,
        )

    @staticmethod
    def _copy_model(obj, updates: dict):
        """å…¼å®¹ Pydantic v1/v2 çš„æ¨¡å‹æ‹·è´"""
        try:
            return obj.model_copy(update=updates)
        except AttributeError:
            return obj.copy(update=updates)

    @staticmethod
    def _extract_invalid_model_id(err_msg: str) -> str | None:
        """ä»é”™è¯¯ä¿¡æ¯ä¸­æå–æ— æƒé™/æ— æ•ˆæ¨¡å‹ID"""
        if not err_msg:
            return None
        if "Incorrect model ID" not in err_msg and "do not have permission to use this model" not in err_msg:
            return None

        patterns = [
            r"use this model\s+([a-zA-Z0-9._-]+)",
            r"model\s+([a-zA-Z0-9._-]+)\s+\(tid:",
            r"'model':\s*'([a-zA-Z0-9._-]+)'",
        ]
        for pattern in patterns:
            match = re.search(pattern, err_msg)
            if match:
                return match.group(1)
        return None

    def _pick_fallback_model(self, bad_model_id: str, group: GroupChat) -> str | None:
        """é€‰æ‹©ä¸€ä¸ªå¤‡ç”¨æ¨¡å‹ç”¨äºè‡ªåŠ¨é™çº§é‡è¯•"""
        candidates: list[str] = []
        candidates.extend(list(_MODEL_CONTEXT_WINDOWS.keys()))
        candidates.extend([m.model_id for m in group.members])
        if group.manager_model:
            candidates.append(group.manager_model)

        for model_id in candidates:
            if model_id and model_id != bad_model_id:
                return model_id
        return None

    def _replace_bad_model(self, group: GroupChat, bad_model_id: str, fallback_model_id: str) -> GroupChat | None:
        """æ„é€ æ›¿æ¢äº†æ— æ•ˆæ¨¡å‹IDçš„ä¸´æ—¶ç¾¤èŠå¯¹è±¡ï¼ˆä»…æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨ï¼‰"""
        replaced = False
        patched_members = []
        for member in group.members:
            if member.model_id == bad_model_id:
                patched_members.append(self._copy_model(member, {"model_id": fallback_model_id}))
                replaced = True
            else:
                patched_members.append(member)

        manager_model = group.manager_model
        if manager_model == bad_model_id:
            manager_model = fallback_model_id
            replaced = True

        if not replaced:
            return None

        return self._copy_model(group, {"members": patched_members, "manager_model": manager_model})

    def _try_build_fallback_group(self, group: GroupChat, err_msg: str) -> tuple[GroupChat | None, str | None]:
        """å‘½ä¸­æ¨¡å‹æƒé™é”™è¯¯æ—¶ï¼Œå°è¯•æ„é€ é™çº§é‡è¯•ç¾¤èŠ"""
        bad_model_id = self._extract_invalid_model_id(err_msg)
        if not bad_model_id:
            return None, None

        fallback_model_id = self._pick_fallback_model(bad_model_id, group)
        if not fallback_model_id:
            return None, f"æ¨¡å‹ `{bad_model_id}` ä¸å¯ç”¨ï¼Œä¸”æ²¡æœ‰å¯ç”¨å¤‡ç”¨æ¨¡å‹ã€‚"

        patched_group = self._replace_bad_model(group, bad_model_id, fallback_model_id)
        if not patched_group:
            return None, f"æ¨¡å‹ `{bad_model_id}` ä¸åœ¨å½“å‰ç¾¤èŠé…ç½®ä¸­ï¼Œæ— æ³•è‡ªåŠ¨æ›¿æ¢ã€‚"

        tip = f"æ£€æµ‹åˆ°æ¨¡å‹ `{bad_model_id}` æ— æƒé™ï¼Œå·²è‡ªåŠ¨å›é€€åˆ° `{fallback_model_id}` é‡è¯•æœ¬è½®è¯·æ±‚ã€‚"
        return patched_group, tip
    
    def remove_member(self, group_id: str, member_id: str) -> bool:
        return self.repo.remove_member(group_id, member_id)
    
    def update_member_task(self, group_id: str, member_id: str, task: str) -> bool:
        return self.repo.update_member_persona(group_id, member_id, task)
    
    # ============ è®¨è®ºåŠŸèƒ½ ============

    async def start_discussion(self, group_id: str, request: DiscussionRequest) -> DiscussionResponse:
        """å¯åŠ¨ç¾¤èŠè®¨è®º"""
        group = self.get_group(group_id)
        if not group or not group.members:
            raise ValueError("ç¾¤èŠä¸å­˜åœ¨æˆ–æ²¡æœ‰æˆå‘˜")
        
        mode = request.mode if request.mode else DiscussionMode.FREE

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        self.repo.save_message(
            group_id=group_id,
            role=MessageRole.USER,
            content=request.content,
            sender_name=request.user_name,
            mode=mode,
            sender_id=None,
            user_id=request.user_id,
        )
        runtime_group = group
        for attempt in range(2):
            member_id_map = {m.name: m.id for m in runtime_group.members}
            try:
                if mode == DiscussionMode.QA:
                    # QA æ¨¡å¼ä¸éœ€è¦å¾ˆé•¿çš„ä¸Šä¸‹æ–‡
                    history_msgs = []
                else:
                    # FREE æ¨¡å¼éœ€è¦ä¸Šä¸‹æ–‡
                    history_msgs = await self._get_history_as_autogen_messages(group_id, limit=50, exclude_last=True)

                # æ¡ä»¶æ³¨å…¥é•¿æœŸè®°å¿†ï¼ˆä»…æ³¨å…¥ä¸€æ¬¡ï¼Œä¸ä¼šæ¯è½®çŒå…¥ï¼‰
                memory_block = await self._build_auto_injection_memory_block(
                    group=runtime_group,
                    user_id=request.user_id,
                    query=request.content,
                )
                if memory_block:
                    history_msgs = [TextMessage(content=memory_block, source="system")] + history_msgs
                toolkits = self._build_toolkits(runtime_group, request.user_id)

                ai_group_chat = AIGroupChat(
                    members=runtime_group.members,
                    user_name=request.user_name,
                    max_rounds=request.max_rounds,
                    mode=mode,
                    manager_model=runtime_group.manager_model,
                    manager_thinking=runtime_group.manager_thinking,
                    manager_temperature=runtime_group.manager_temperature,
                    history=history_msgs,
                    shared_tools=toolkits.member_tools,
                    manager_tools=toolkits.manager_tools,
                )

                # è¿è¡Œè®¨è®º
                if mode == DiscussionMode.QA:
                    messages_data = []
                    async for msg in ai_group_chat.stream_qa_discussion(request.content):
                        messages_data.append(msg)
                else:
                    messages_data = await ai_group_chat.discuss(
                        question=request.content,
                        max_rounds=request.max_rounds,
                    )

                # ä¿å­˜ç»“æœ
                result_messages = []
                for msg_data in messages_data:
                    message = self.repo.save_message(
                        group_id=group_id,
                        role=MessageRole.ASSISTANT,
                        content=msg_data["content"],
                        sender_name=msg_data["sender"],
                        mode=mode,
                        sender_id=member_id_map.get(msg_data["sender"]),
                        user_id=request.user_id,
                    )
                    result_messages.append(message)

                if ai_group_chat.was_terminated_by_system():
                    notice = self.repo.save_message(
                        group_id=group_id,
                        role=MessageRole.SYSTEM,
                        content=self._build_system_termination_notice(
                            ai_group_chat.last_system_termination_reason
                        ),
                        sender_name="ç³»ç»Ÿ",
                        mode=mode,
                        sender_id=None,
                        user_id=request.user_id,
                    )
                    result_messages.append(notice)

                self._schedule_memory_archive(group=group, user_id=request.user_id, reason="discussion_sync")
                return DiscussionResponse(messages=result_messages, summary=None)
            except Exception as e:
                err_msg = str(e)
                if attempt == 0:
                    fallback_group, tip = self._try_build_fallback_group(runtime_group, err_msg)
                    if fallback_group:
                        logger.warning(tip)
                        runtime_group = fallback_group
                        continue
                logger.error(f"è®¨è®ºæ‰§è¡Œå¤±è´¥: {err_msg}")
                if "RateLimitError" in err_msg or "429" in err_msg:
                    raise ValueError("æ¨¡å‹è°ƒç”¨è§¦å‘é™æµï¼ˆ429ï¼‰ï¼šå…è´¹é¢åº¦å·²ç”¨å°½ï¼Œè¯·åˆ‡æ¢ä»˜è´¹æ¨¡å‹æˆ–ç¨åé‡è¯•ã€‚")
                if self._extract_invalid_model_id(err_msg):
                    raise ValueError(
                        f"æ¨¡å‹ä¸å¯ç”¨æˆ–æ— æƒé™ï¼š{err_msg}\nè¯·åœ¨æˆå‘˜/ç®¡ç†å‘˜è®¾ç½®é‡Œåˆ‡æ¢åˆ°å¯ç”¨æ¨¡å‹åé‡è¯•ã€‚"
                    )
                raise ValueError(f"è®¨è®ºæ‰§è¡Œå¤±è´¥: {err_msg}")

        raise ValueError("è®¨è®ºæ‰§è¡Œå¤±è´¥ï¼šè‡ªåŠ¨å›é€€åä»æœªæˆåŠŸã€‚")
    
    async def stream_discussion(self, group_id: str, request: DiscussionRequest):
        """æµå¼å¯åŠ¨ç¾¤èŠè®¨è®º"""
        group = self.get_group(group_id)
        if not group or not group.members:
            raise ValueError("ç¾¤èŠä¸å­˜åœ¨æˆ–æ²¡æœ‰æˆå‘˜")
        
        mode = request.mode if request.mode else DiscussionMode.FREE

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        self.repo.save_message(
            group_id=group_id,
            role=MessageRole.USER,
            content=request.content,
            sender_name=request.user_name,
            mode=mode,
            sender_id=None,
            user_id=request.user_id,
        )
        external_termination = ExternalTermination()
        await self._register_active_discussion(group_id, external_termination)
        runtime_group = group
        try:
            for attempt in range(2):
                member_id_map = {m.name: m.id for m in runtime_group.members}
                emitted_count = 0
                try:
                    # è·å–å†å²æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
                    # æ³¨æ„: exclude_last=True æ˜¯ä¸ºäº†é¿å…é‡å¤åŒ…å«åˆšåˆšä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œ
                    # å› ä¸ºåœ¨ AutoGen ä¸­ï¼Œç”¨æˆ·çš„æé—®é€šå¸¸ä½œä¸º initiate_chat çš„ message å‚æ•°ä¼ å…¥
                    history_msgs = await self._get_history_as_autogen_messages(group_id, limit=50, exclude_last=True)
                    memory_block = await self._build_auto_injection_memory_block(
                        group=runtime_group,
                        user_id=request.user_id,
                        query=request.content,
                    )
                    if memory_block:
                        history_msgs = [TextMessage(content=memory_block, source="system")] + history_msgs
                    toolkits = self._build_toolkits(runtime_group, request.user_id)

                    ai_group_chat = AIGroupChat(
                        members=runtime_group.members,
                        user_name=request.user_name,
                        max_rounds=request.max_rounds,
                        mode=mode,
                        manager_model=runtime_group.manager_model,
                        manager_thinking=runtime_group.manager_thinking,
                        manager_temperature=runtime_group.manager_temperature,
                        history=history_msgs,
                        shared_tools=toolkits.member_tools,
                        manager_tools=toolkits.manager_tools,
                        external_termination=external_termination,
                    )

                    if mode == DiscussionMode.QA:
                        generator = ai_group_chat.stream_qa_discussion(request.content)
                    else:
                        generator = ai_group_chat.stream_discuss(request.content, request.max_rounds)

                    async for msg_data in generator:
                        message = self.repo.save_message(
                            group_id=group_id,
                            role=MessageRole.ASSISTANT,
                            content=msg_data["content"],
                            sender_name=msg_data["sender"],
                            mode=mode,
                            sender_id=member_id_map.get(msg_data["sender"]),
                            user_id=request.user_id,
                        )
                        emitted_count += 1
                        yield message

                    if ai_group_chat.was_terminated_by_system():
                        notice = self.repo.save_message(
                            group_id=group_id,
                            role=MessageRole.SYSTEM,
                            content=self._build_system_termination_notice(
                                ai_group_chat.last_system_termination_reason
                            ),
                            sender_name="ç³»ç»Ÿ",
                            mode=mode,
                            sender_id=None,
                            user_id=request.user_id,
                        )
                        emitted_count += 1
                        yield notice
                    elif ai_group_chat.was_terminated_externally():
                        notice = self.repo.save_message(
                            group_id=group_id,
                            role=MessageRole.SYSTEM,
                            content=self._build_manual_termination_notice(),
                            sender_name="ç³»ç»Ÿ",
                            mode=mode,
                            sender_id=None,
                            user_id=request.user_id,
                        )
                        emitted_count += 1
                        yield notice
                    self._schedule_memory_archive(group=group, user_id=request.user_id, reason="discussion_stream")
                    return
                except Exception as e:
                    err_msg = str(e)
                    bad_model_id = self._extract_invalid_model_id(err_msg)
                    if attempt == 0 and emitted_count == 0:
                        fallback_group, tip = self._try_build_fallback_group(runtime_group, err_msg)
                        if fallback_group:
                            logger.warning(tip)
                            runtime_group = fallback_group
                            continue
                    logger.error(f"è®¨è®ºæµå¼æ‰§è¡Œå¤±è´¥: {err_msg}")
                    if "RateLimitError" in err_msg or "429" in err_msg:
                        raise ValueError("æ¨¡å‹è°ƒç”¨è§¦å‘é™æµï¼ˆ429ï¼‰ï¼šå…è´¹é¢åº¦å·²ç”¨å°½ï¼Œè¯·åˆ‡æ¢ä»˜è´¹æ¨¡å‹æˆ–ç¨åé‡è¯•ã€‚")
                    if bad_model_id:
                        # æµå¼æ¨¡å¼å¯èƒ½å·²äº§ç”Ÿéƒ¨åˆ†å›å¤ï¼›æ­¤æ—¶ä¸æŠ›å¼‚å¸¸ä¸­æ–­å‰ç«¯ï¼Œè€Œæ˜¯ç»™å‡ºç³»ç»Ÿæç¤ºå¹¶ç»“æŸæœ¬è½®
                        if emitted_count > 0:
                            tip = (
                                f"æˆå‘˜æ¨¡å‹ `{bad_model_id}` æ— æƒé™ï¼Œå·²æå‰ç»“æŸæœ¬è½®è®¨è®ºã€‚"
                                "è¯·åœ¨æˆå‘˜/ç®¡ç†å‘˜è®¾ç½®é‡Œåˆ‡æ¢åˆ°å¯ç”¨æ¨¡å‹åé‡è¯•ã€‚"
                            )
                            logger.warning(tip)
                            notice = self.repo.save_message(
                                group_id=group_id,
                                role=MessageRole.SYSTEM,
                                content=tip,
                                sender_name="ç³»ç»Ÿ",
                                mode=mode,
                                sender_id=None,
                                user_id=request.user_id,
                            )
                            yield notice
                            self._schedule_memory_archive(group=group, user_id=request.user_id, reason="discussion_stream")
                            return
                        raise ValueError(
                            f"æ¨¡å‹ä¸å¯ç”¨æˆ–æ— æƒé™ï¼š{err_msg}\nè¯·åœ¨æˆå‘˜/ç®¡ç†å‘˜è®¾ç½®é‡Œåˆ‡æ¢åˆ°å¯ç”¨æ¨¡å‹åé‡è¯•ã€‚"
                        )
                    raise ValueError(f"è®¨è®ºæ‰§è¡Œå¤±è´¥: {err_msg}")
        finally:
            await self._clear_active_discussion(group_id, external_termination)
            
    async def summarize_discussion(self, group_id: str, request: SummarizeRequest):
        """å¯¹ç¾¤èŠè¿›è¡Œæ€»ç»“"""
        group = self.get_group(group_id)
        if not group: return
        runtime_group = group
        for attempt in range(2):
            member_id_map = {m.name: m.id for m in runtime_group.members}
            try:
                history_msgs = await self._get_history_as_autogen_messages(group_id, limit=100)
                memory_block = await self._build_auto_injection_memory_block(
                    group=runtime_group,
                    user_id=request.user_id,
                    query=request.instruction or "æ€»ç»“å¹¶æç‚¼ç¾¤èŠç»“è®º",
                )
                if memory_block:
                    history_msgs = [TextMessage(content=memory_block, source="system")] + history_msgs
                toolkits = self._build_toolkits(runtime_group, request.user_id)

                ai_group_chat = AIGroupChat(
                    members=runtime_group.members,
                    user_name=request.user_name or "User",
                    mode=DiscussionMode.FREE,
                    manager_model=runtime_group.manager_model,
                    manager_thinking=runtime_group.manager_thinking,
                    manager_temperature=runtime_group.manager_temperature,
                    history=history_msgs,
                    shared_tools=toolkits.member_tools,
                )

                result = await ai_group_chat.summarize(request.instruction)
                message = self.repo.save_message(
                    group_id=group_id,
                    role=MessageRole.ASSISTANT,
                    content=result["content"],
                    sender_name=result["sender"],
                    mode=DiscussionMode.FREE,
                    sender_id=member_id_map.get(result["sender"]),
                    user_id=request.user_id,
                )
                self._schedule_memory_archive(group=group, user_id=request.user_id, reason="summarize")
                yield message
                return
            except Exception as e:
                err_msg = str(e)
                if attempt == 0:
                    fallback_group, tip = self._try_build_fallback_group(runtime_group, err_msg)
                    if fallback_group:
                        logger.warning(tip)
                        runtime_group = fallback_group
                        continue
                logger.error(f"æ€»ç»“æ‰§è¡Œå¤±è´¥: {err_msg}")
                if "RateLimitError" in err_msg or "429" in err_msg:
                    raise ValueError("æ€»ç»“è§¦å‘é™æµï¼ˆ429ï¼‰ï¼šå…è´¹é¢åº¦å·²ç”¨å°½ï¼Œè¯·åˆ‡æ¢ä»˜è´¹æ¨¡å‹æˆ–ç¨åé‡è¯•ã€‚")
                if self._extract_invalid_model_id(err_msg):
                    raise ValueError(
                        f"æ¨¡å‹ä¸å¯ç”¨æˆ–æ— æƒé™ï¼š{err_msg}\nè¯·åœ¨æˆå‘˜/ç®¡ç†å‘˜è®¾ç½®é‡Œåˆ‡æ¢åˆ°å¯ç”¨æ¨¡å‹åé‡è¯•ã€‚"
                    )
                raise ValueError(f"æ€»ç»“æ‰§è¡Œå¤±è´¥: {err_msg}")

    def _schedule_memory_archive(self, group: GroupChat, user_id: str, reason: str) -> None:
        """åå°å¼‚æ­¥å½’æ¡£é•¿æœŸè®°å¿†ï¼Œä¸é˜»å¡ä¸»é“¾è·¯"""
        async def runner():
            try:
                await self.long_term_memory.archive_incremental(
                    group=group,
                    user_id=user_id,
                    force=True,
                    reason=reason,
                )
            except Exception as e:
                logger.error(f"åå°é•¿æœŸè®°å¿†å½’æ¡£å¤±è´¥: {e}")
        asyncio.create_task(runner())
    
    async def _get_history_as_autogen_messages(self, group_id: str, limit: int = 50, exclude_last: bool = False) -> list[TextMessage]:
        """
        è·å–ç¾¤èŠå†å²å¹¶è½¬æ¢ä¸º AutoGen æ ¼å¼ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
        
        åŒ…å«ä¸Šä¸‹æ–‡å‹ç¼©é€»è¾‘ï¼šå½“ Token è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨å‹ç¼©
        ä¸Šä¸‹æ–‡çª—å£å¤§å°åŠ¨æ€è®¾ç½®ä¸ºç¾¤èŠä¸­æ¨¡å‹çš„æœ€å°å€¼
        å‹ç¼©è¿‡ç¨‹ä½¿ç”¨å¼‚æ­¥ LLM è°ƒç”¨ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
        """
        # è·å–ç¾¤èŠä¿¡æ¯ä»¥ç¡®å®šæœ€å°ä¸Šä¸‹æ–‡çª—å£
        group = self.get_group(group_id)
        if group:
            min_context_window = self.get_min_context_window(group)
            self.context_manager.set_max_tokens(min_context_window)
            
            # åŠ¨æ€åº”ç”¨å‹ç¼©é˜ˆå€¼é…ç½®
            self.context_manager.threshold_ratio = group.compression_threshold
            self.context_manager.threshold_tokens = int(self.context_manager.max_tokens * self.context_manager.threshold_ratio)
        
        # 1. å°è¯•åŠ è½½æœ€æ–°çš„ä¸Šä¸‹æ–‡å¿«ç…§
        snapshot = self.repo.get_latest_snapshot(group_id)
        
        final_messages = []
        messages_to_process = []
        last_processed_msg_id = None
        snapshot_loaded = False
        
        if snapshot:
            try:
                # ååºåˆ—åŒ–å¿«ç…§å†…å®¹
                import json
                snapshot_data = json.loads(snapshot['context_content'])
                
                # å°è¯•ä½¿ç”¨ Pydantic çš„è§£ææ–¹æ³•ï¼Œå…¼å®¹ v1 å’Œ v2
                try:
                    final_messages = [Message.model_validate(item) for item in snapshot_data]
                except AttributeError:
                    # Pydantic v1 fallback
                    final_messages = [Message.parse_obj(item) for item in snapshot_data]
                except Exception:
                    # Fallback manually
                    final_messages = [Message(**item) for item in snapshot_data]
                
                last_processed_msg_id = snapshot['last_message_id']
                logger.info(f"ğŸ“¸ åŠ è½½ä¸Šä¸‹æ–‡å¿«ç…§æˆåŠŸ (ID: {snapshot['id']}), Token: {snapshot['token_count']}")
                
                # åŠ è½½å¢é‡æ¶ˆæ¯
                messages_to_process = self.repo.get_messages_after(group_id, last_processed_msg_id)
                logger.info(f"ğŸ“¥ å¢é‡åŠ è½½äº† {len(messages_to_process)} æ¡æ–°æ¶ˆæ¯")
                snapshot_loaded = True
                
            except Exception as e:
                logger.error(f"âŒ åŠ è½½å¿«ç…§å¤±è´¥ï¼Œå›é€€åˆ°å…¨é‡åŠ è½½: {e}")
                final_messages = []
                snapshot_loaded = False
        
        if not snapshot_loaded:
            # å…¨é‡åŠ è½½
            messages_to_process = self.repo.get_messages(group_id, limit=0)
            logger.info(f"ğŸ“š å…¨é‡åŠ è½½å†å²æ¶ˆæ¯ï¼Œæ€»æ•°: {len(messages_to_process)}")
        
        if exclude_last and messages_to_process:
            messages_to_process = messages_to_process[:-1]
        
        # åˆ†æ‰¹ç´¯åŠ ä¸å‹ç¼©ç­–ç•¥
        current_batch = []
        save_snapshot = False
        
        # å¦‚æœå¿«ç…§æœ¬èº«å·²ç»è¶…é™ï¼ˆä¾‹å¦‚çª—å£è®¾ç½®å˜å°äº†ï¼‰ï¼Œä¹Ÿéœ€è¦å‹ç¼©
        if self.context_manager.should_compress(final_messages):
             logger.info("âš ï¸ å¿«ç…§å†…å®¹è¶…è¿‡å½“å‰é˜ˆå€¼ï¼Œé‡æ–°å‹ç¼©...")
             final_messages = await self.context_manager.process_async(final_messages)
             save_snapshot = True
        
        for msg in messages_to_process:
            current_batch.append(msg)
            last_processed_msg_id = msg.id
            
            check_context = final_messages + current_batch
            
            if self.context_manager.should_compress(check_context):
                logger.info(f"âš¡ï¸ è§¦å‘åˆ†æ‰¹å‹ç¼©å¾ªç¯ï¼Œå½“å‰æ€»æ•°: {len(check_context)}")
                final_messages = await self.context_manager.process_async(check_context)
                current_batch = []
                save_snapshot = True
        
        # å¤„ç†å‰©ä½™çš„ batch
        if current_batch:
            final_messages = final_messages + current_batch
            if self.context_manager.should_compress(final_messages):
                logger.info(f"âš¡ï¸ è§¦å‘æœ€ç»ˆå‹ç¼©")
                final_messages = await self.context_manager.process_async(final_messages)
                save_snapshot = True
            elif snapshot_loaded and current_batch:
                # å³ä½¿æ²¡æœ‰è§¦å‘å‹ç¼©ï¼Œä½†æˆ‘ä»¬æœ‰æ–°çš„å¢é‡æ¶ˆæ¯ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©æ›´æ–°å¿«ç…§
                # ä¸ºäº†ä¸‹æ¬¡æ›´å¿«çš„åŠ è½½ï¼Œè¿™é€šå¸¸æ˜¯å¥½çš„
                save_snapshot = True

        # ä¿å­˜æ–°çš„å¿«ç…§
        if save_snapshot and last_processed_msg_id and final_messages:
             try:
                 token_count = self.context_manager.count_messages_tokens(final_messages)
                 self.repo.save_snapshot(group_id, last_processed_msg_id, final_messages, token_count)
                 logger.info(f"ğŸ’¾ ä¸Šä¸‹æ–‡å¿«ç…§å·²æ›´æ–° (Msg: {last_processed_msg_id})")
             except Exception as e:
                 logger.error(f"âŒ ä¿å­˜å¿«ç…§å¤±è´¥: {e}")
        
        # è½¬æ¢ä¸º AutoGen æ ¼å¼
        autogen_msgs = []
        for msg in final_messages:
            source = "user" if msg.role == MessageRole.USER else _sanitize_name(msg.sender_name)
            autogen_msgs.append(TextMessage(content=msg.content, source=source))
        return autogen_msgs

    async def get_context_stats(self, group_id: str) -> dict:
        """è·å–ç¾¤èŠä¸Šä¸‹æ–‡ç»Ÿè®¡ï¼ˆç”¨äº API æ‹‰å–ä¸ SSE å®æ—¶æ¨é€ï¼‰"""
        group = self.get_group(group_id)
        if not group:
            raise ValueError("ç¾¤èŠä¸å­˜åœ¨")

        min_context_window = self.get_min_context_window(group)
        self.context_manager.set_max_tokens(min_context_window)

        autogen_msgs = await self._get_history_as_autogen_messages(group_id, limit=0)
        current_tokens = sum(self.context_manager.count_tokens(m.content) for m in autogen_msgs)

        raw_messages = self.get_messages(group_id, limit=1000)
        type_counts = Counter(msg.message_type.value for msg in raw_messages)
        member_windows = {
            m.name: _MODEL_CONTEXT_WINDOWS.get(m.model_id, self.DEFAULT_CONTEXT_WINDOW)
            for m in group.members
        } if group.members else {}
        memory_stats = self.long_term_memory.get_group_stats(group_id)

        return {
            "current_tokens": current_tokens,
            "message_count": len(autogen_msgs),
            "type_distribution": dict(type_counts),
            "compression_config": {
                "max_tokens": self.context_manager.max_tokens,
                "threshold_ratio": group.compression_threshold,
                "threshold_tokens": int(self.context_manager.max_tokens * group.compression_threshold),
            },
            "dynamic_context_window": {
                "min_context_window": min_context_window,
                "member_windows": member_windows,
            },
            "memory_stats": memory_stats,
        }
    
    def get_messages(self, group_id: str, limit: int = 50) -> list[Message]:
        return self.repo.get_messages(group_id, limit)


def _sanitize_name(name: str) -> str:
    """å°†åç§°è½¬æ¢ä¸º AutoGen å…¼å®¹æ ¼å¼"""
    if not name:
        return "unknown"
    name = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    if not re.match(r'^[a-zA-Z_]', name):
        name = '_' + name
    return name


# å…¨å±€æœåŠ¡å®ä¾‹
chat_service = ChatService()
