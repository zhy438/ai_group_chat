"""åŸºäº AutoGen çš„ AI ç¾¤èŠå®ç° (æ–°ç‰ˆ API)"""

import re
import asyncio
from typing import AsyncGenerator
from loguru import logger
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.teams import SelectorGroupChat, RoundRobinGroupChat
from autogen_agentchat.conditions import MaxMessageTermination
from autogen_agentchat.base import TaskResult
from autogen_core.models import ModelInfo
from autogen_ext.models.openai import OpenAIChatCompletionClient

from ..models import AIMember, DiscussionMode
from ..config import get_settings
from autogen_agentchat.teams import SelectorGroupChat, RoundRobinGroupChat
from autogen_agentchat.conditions import MaxMessageTermination
from autogen_agentchat.base import TaskResult
from autogen_core.models import ModelInfo
from autogen_ext.models.openai import OpenAIChatCompletionClient

from ..models import AIMember, DiscussionMode
from ..config import get_settings


# é»˜è®¤ç®¡ç†å‘˜æ¨¡å‹
DEFAULT_MANAGER_MODEL = "gpt-4o-mini"


def _sanitize_name(name: str) -> str:
    """å°†åç§°è½¬æ¢ä¸º AutoGen å…¼å®¹æ ¼å¼"""
    name = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    if not re.match(r'^[a-zA-Z_]', name):
        name = '_' + name
    return name


def _get_model_client(
    model_id: str,
    temperature: float = 0.7,
    thinking: bool = False,
) -> OpenAIChatCompletionClient:
    """è·å–æ¨¡å‹å®¢æˆ·ç«¯"""
    settings = get_settings()
    
    model_info = ModelInfo(
        vision=False,
        function_calling=True,
        json_output=True,
        family="unknown",
    )
    
    extra_kwargs = {}
    if thinking:
        extra_kwargs["extra_body"] = {"enable_thinking": True}
    
    return OpenAIChatCompletionClient(
        model=model_id,
        base_url=settings.ai_api_base,
        api_key=settings.ai_api_key,
        model_info=model_info,
        temperature=temperature,
        **extra_kwargs,
    )


def _build_system_prompt(member: AIMember, all_members: list[AIMember], mode: DiscussionMode) -> str:
    """æ„å»ºæˆå‘˜çš„ç³»ç»Ÿæç¤ºè¯"""
    
    # ä½¿ç”¨ sanitized name ä½œä¸ºèº«ä»½æ ‡è¯†
    my_name = _sanitize_name(member.model_id)
    other_members = [_sanitize_name(m.model_id) for m in all_members if m.model_id != member.model_id]
    members_str = "ã€".join(other_members) if other_members else "æš‚æ— å…¶ä»–æˆå‘˜"
    
    base_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªaiæ™ºèƒ½åŠ©æ‰‹ï¼Œä½ çš„åå­—æ˜¯"{my_name}"ï¼Œä½ æ­£åœ¨ä¸€ä¸ªç¾¤èŠé‡Œå’Œå…¶ä»–aiåŠ©æ‰‹èŠå¤©ï¼Œç›®çš„æ˜¯è§£å†³ç”¨æˆ·çš„é—®é¢˜

ã€ç¾¤æˆå‘˜åˆ—è¡¨ã€‘
ç¾¤é‡Œé™¤äº†ä½ ä¹‹å¤–è¿˜æœ‰ï¼š{members_str}
ï¼ˆå¦‚æœè¦@æŸäººï¼Œè¯·ä½¿ç”¨ä¸Šé¢çš„åå­—ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„åå­—ï¼‰

ã€é‡è¦è§„åˆ™ã€‘
1. ä½ ä»¬çš„ä»»åŠ¡æ˜¯è§£å†³ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸€åˆ‡çš„å›ç­”éƒ½æ˜¯è¦ä»¥è§£å†³ç”¨æˆ·é—®é¢˜ä¸ºç›®çš„
2. å¯ä»¥ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼Œå¶å°”ç”¨è¡¨æƒ…ç¬¦å·
3. å¦‚æœä¸çŸ¥é“å°±è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ 
4. å¯ä»¥@å…¶ä»–ç¾¤å‹çš„åå­—æ¥å›åº”taçš„è§‚ç‚¹ï¼ˆä¸å¼ºåˆ¶ï¼‰ï¼Œä½†ç»å¯¹ä¸è¦@è‡ªå·±ï¼ˆä½ çš„åå­—æ˜¯"{my_name}"ï¼‰
5. å›å¤éœ€è¦è¨€ç®€æ„èµ…ï¼Œé™¤éé—®é¢˜ç¡®å®éœ€è¦è¯¦ç»†è§£ç­”
6. å¦‚æœå·²ç»å¾—å‡ºç»“è®ºäº†ï¼Œå¯ä»¥ç®€å•é™„å’Œæˆ–ç‚¹è¯„ï¼Œä¸è¦é‡å¤ä¹‹å‰è¯´è¿‡çš„è¯

ã€ä½ çš„äººè®¾ã€‘
{member.description or 'æ™®é€šç¾¤å‹ï¼Œæ€§æ ¼éšå’Œ'}

ã€ç»å¯¹ç¦æ­¢ã€‘
ç»å¯¹ä¸è¦åœ¨å›å¤ä¸­åŒ…å« @{my_name}ï¼è¿™æ˜¯åœ¨@ä½ è‡ªå·±ï¼Œæ˜¯é”™è¯¯çš„ï¼
"""
    
    # æ ¹æ®æ¨¡å¼è°ƒæ•´æç¤ºè¯
    if mode == DiscussionMode.QA:
        base_prompt += "\nã€å½“å‰æ¨¡å¼ï¼šä¸€é—®ä¸€ç­” (QA)ã€‘\nè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›é«˜è´¨é‡ã€ç‹¬ç«‹çš„è§è§£ã€‚\nå°½åŠ›å‡å°‘ä¸å…¶ä»–ç¾¤æˆå‘˜çš„é—²èŠæˆ–äº’åŠ¨ï¼Œé™¤éå¿…é¡»å¼•ç”¨ä»–äººçš„è§‚ç‚¹ã€‚\né‡ç‚¹åœ¨äºå±•ç¤ºä½ ç‹¬ç‰¹çš„è§†è§’å’ŒçŸ¥è¯†ã€‚"
    else:
        base_prompt += "\nã€å½“å‰æ¨¡å¼ï¼šè‡ªç”±è®¨è®ºã€‘\nè‡ªç„¶åœ°å‚ä¸è®¨è®ºï¼Œç§¯æä¸å…¶ä»–æˆå‘˜äº’åŠ¨ï¼Œå¯ä»¥è¡¥å……ã€é™„å’Œæˆ–æå‡ºä¸åŒçœ‹æ³•ã€‚\né€šè¿‡åä½œå’Œäº¤æµæ¥è§£å†³é—®é¢˜ã€‚"
    
    return base_prompt


class AIGroupChat:
    """
    åŸºäº AutoGen çš„ AI ç¾¤èŠ
    
    ä½¿ç”¨åŸç”Ÿ Team ç»„ä»¶ (SelectorGroupChat / RoundRobinGroupChat)
    """
    
    def __init__(
        self,
        members: list[AIMember],
        user_name: str = "ç”¨æˆ·",
        max_rounds: int = 2,
        mode: DiscussionMode = DiscussionMode.FREE,
        manager_model: str = DEFAULT_MANAGER_MODEL,
        manager_thinking: bool = False,
        manager_temperature: float = 0.7,
        history: list[TextMessage] = [],
    ):
        # è®¡ç®—æœ€å¤§æ¶ˆæ¯æ•°ï¼šå†å²æ¶ˆæ¯æ•° + æœ¬è½®é™åˆ¶ (æ¯è½®æ¯ä¸ªæˆå‘˜å‘è¨€ä¸€æ¬¡ + ç”¨æˆ·é—®é¢˜)
        # æ³¨æ„ï¼šAutoGen çš„ MaxMessageTermination è®¡ç®—çš„æ˜¯æ€»æ¶ˆæ¯æ•°
        max_messages = len(history) + (max_rounds * len(members) + 1)
        self.members = members
        self.user_name = user_name
        self.mode = mode
        self.history = history
        self.manager_model = manager_model
        self.manager_thinking = manager_thinking
        self.manager_temperature = manager_temperature
        self.agents: list[AssistantAgent] = []
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–ç¾¤èŠ: {len(members)} ä¸ªæˆå‘˜, æ¨¡å¼: {mode}, ç®¡ç†å‘˜: {manager_model}")
        
        # åç§°æ˜ å°„
        self.name_map = {}

        # åˆ›å»º Agents
        for member in members:
            # å¿…é¡»ä½¿ç”¨åˆæ³•çš„ Python æ ‡è¯†ç¬¦
            agent_name = _sanitize_name(member.model_id)
            self.name_map[agent_name] = member.model_id
            
            logger.info(f"  ğŸ‘¤ åˆ›å»º Agent: {agent_name} (åŸå: {member.model_id})")
            
            agent = AssistantAgent(
                name=agent_name,
                system_message=_build_system_prompt(member, members, mode),
                model_client=_get_model_client(
                    member.model_id,
                    temperature=member.temperature,
                    thinking=member.thinking,
                ),
            )
            self.agents.append(agent)
        
        # åˆ›å»º Team
        termination = MaxMessageTermination(max_messages=max_messages)
        
        # è‡ªå®šä¹‰ selector æç¤ºè¯ï¼ˆç¾¤ç®¡ç†å‘˜ï¼‰
        selector_prompt = """ä½ æ˜¯ä¸€ä¸ªç¾¤èŠçš„ä¸»æŒäººï¼Œè´Ÿè´£å†³å®šä¸‹ä¸€ä¸ªè°æ¥å‘è¨€ã€‚

å½“å‰ç¾¤æˆå‘˜ï¼š{participants}

å„æˆå‘˜ç®€ä»‹ï¼š
{roles}

æœ€è¿‘çš„å¯¹è¯å†å²ï¼š
{history}

ã€é€‰æ‹©è§„åˆ™ã€‘
1. ä¼˜å…ˆè®©è¿˜æ²¡å‘è¨€è¿‡æˆ–å‘è¨€è¾ƒå°‘çš„æˆå‘˜å‘è¨€
2. å¦‚æœæœ‰äººè¢«@äº†ï¼Œä¼˜å…ˆè®©è¢«@çš„äººå›å¤
3. é¿å…åŒä¸€ä¸ªäººè¿ç»­å‘è¨€
4. å¦‚æœè®¨è®ºå·²ç»æ”¶æ•›ï¼ˆå¤§å®¶æ„è§ä¸€è‡´ï¼‰ï¼Œå¯ä»¥è®©æ–°çš„è§’åº¦çš„äººå‘è¨€

è¯·åªå›å¤ä¸‹ä¸€ä¸ªå‘è¨€è€…çš„åå­—ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""
        
        self.team = SelectorGroupChat(
            participants=self.agents,
            model_client=_get_model_client(
                manager_model,
                temperature=manager_temperature,
                thinking=manager_thinking,
            ),
            termination_condition=termination,
            selector_prompt=selector_prompt,
        )
    

    
    async def stream_qa_discussion(self, question: str) -> AsyncGenerator[dict, None]:
        """
        [QAæ¨¡å¼] ä¸€é—®ä¸€ç­”å¹¶å‘æ¨¡å¼
        """
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘é—®ç­” (QA): {question}")
        
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯
        user_msg = TextMessage(content=question, source="user")
        
        # å®šä¹‰å•ä¸ª Agent çš„ç”Ÿæˆä»»åŠ¡
        async def generate_reply(agent):
            # è·å– agent å¯¹åº”çš„åŸå§‹ name
            display_name = self.name_map.get(agent.name, agent.name)
            
            try:
                # ä½¿ç”¨ agent.on_messages ç›´æ¥ç”Ÿæˆå›å¤
                # å°†å†å²æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡ä¼ å…¥
                messages = self.history + [user_msg]
                response = await agent.on_messages(
                    messages=messages,
                    cancellation_token=None,
                )
                
                content = response.chat_message.content
                logger.info(f"âœ… {display_name} å›å¤å®Œæˆ")
                return {"sender": display_name, "content": content}
                
            except Exception as e:
                logger.error(f"âŒ {display_name} ç”Ÿæˆå¤±è´¥: {e}")
                return {"sender": display_name, "content": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [generate_reply(agent) for agent in self.agents]
        
        # ä½¿ç”¨ as_completed é€ä¸ª yield å®Œæˆçš„ç»“æœ
        for coro in asyncio.as_completed(tasks):
            result = await coro
            yield result

    
    async def stream_discuss(
        self,
        question: str,
        max_rounds: int = 2,
    ) -> AsyncGenerator[dict, None]:
        """
        æµå¼è®¨è®ºï¼Œä½¿ç”¨ Team çš„åŸç”Ÿæµå¼æ–¹æ³•
        """
        logger.info(f"ğŸš€ å¼€å§‹è®¨è®º: {question}")
        
        msg_count = 0
        # æ”¶é›†æ¡†æ¶è¿”å›çš„åŸå§‹æ¶ˆæ¯å¯¹è±¡
        framework_messages = []

        # è®°å½•å†å²æ¶ˆæ¯æŒ‡çº¹ä»¥é˜²å›æ˜¾
        history_signatures = set()
        if self.history:
            for h in self.history:
                history_signatures.add((h.source, h.content))
        
        task = self.history + [TextMessage(content=question, source="user")] if self.history else question
        async for message in self.team.run_stream(task=task):
            # TaskResult è¡¨ç¤ºç»“æŸ
            if isinstance(message, TaskResult):
                logger.info(f"âœ… è®¨è®ºç»“æŸï¼Œå…± {msg_count} æ¡ AI å›å¤")
                # è¾“å‡ºæœ€ç»ˆçš„æ¡†æ¶å¯¹è¯å†å²
                self._log_framework_history(message.messages, "æœ€ç»ˆ")
                break
            
            # æ”¶é›†æ¶ˆæ¯
            framework_messages.append(message)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ source å±æ€§
            if hasattr(message, 'source'):
                # è·³è¿‡ç”¨æˆ·æ¶ˆæ¯
                if message.source == "user":
                    continue
                
                # è·³è¿‡å†å²æ¶ˆæ¯å›æ˜¾
                if self.history and (message.source, message.content) in history_signatures:
                    logger.debug(f"ğŸš« è·³è¿‡å†å²æ¶ˆæ¯å›æ˜¾: {message.source}")
                    continue
                
                display_name = self.name_map.get(message.source, message.source)
                
                # è¾“å‡º selector é€‰æ‹©ä¿¡æ¯
                logger.info(f"ğŸ¯ Selector é€‰æ‹©å‘è¨€: {display_name}")
                
                if hasattr(message, 'content'):
                    content = message.content if isinstance(message.content, str) else str(message.content)
                    if content.strip():
                        msg_count += 1
                        
                        # è¾“å‡ºå½“å‰æ¡†æ¶æ”¶é›†çš„å¯¹è¯å†å²
                        self._log_framework_history(framework_messages, "å½“å‰")
                        
                        yield {"sender": display_name, "content": content}
    
    def _log_framework_history(self, messages: list, label: str = ""):
        """è¾“å‡ºæ¡†æ¶ç®¡ç†çš„å¯¹è¯å†å²"""
        logger.info("=" * 60)
        logger.info(f"ğŸ“‹ {label}å¯¹è¯å†å² ({len(messages)} æ¡):")
        for i, msg in enumerate(messages):
            src = getattr(msg, 'source', 'unknown')
            # è½¬æ¢ä¸ºæ˜¾ç¤ºå
            display_src = self.name_map.get(src, src)
            content = getattr(msg, 'content', str(msg))
            msg_type = type(msg).__name__
            if isinstance(content, str):
                text = content[:120] + '...' if len(content) > 120 else content
            else:
                text = str(content)[:120]
            logger.info(f"  [{i+1}] ({msg_type}) {display_src}: {text}")
        logger.info("=" * 60)
    
    async def discuss(
        self,
        question: str,
        max_rounds: int = 2,
    ) -> list[dict]:
        """
        åŒæ­¥è®¨è®ºï¼Œè¿”å›æ‰€æœ‰æ¶ˆæ¯
        """
        messages = []
        async for msg in self.stream_discuss(question, max_rounds):
            messages.append(msg)
        return messages

    async def summarize(self, instruction: str = "è¯·æ€»ç»“ä¸Šè¿°è®¨è®º") -> dict:
        """
        ä½¿ç”¨ç®¡ç†å‘˜æ¨¡å‹å¯¹å†å²è®¨è®ºè¿›è¡Œæ€»ç»“
        """
        logger.info(f"ğŸ“ å¼€å§‹æ€»ç»“è®¨è®º: {instruction}")
        
        # åˆ›å»ºæ€»ç»“ Agent (å¤ç”¨ Manager Model)
        model_client = _get_model_client(
            self.manager_model, 
            thinking=self.manager_thinking, 
            temperature=self.manager_temperature
        )
        agent = AssistantAgent(
            name="DialogSummarizer",
            model_client=model_client,
            system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¨è®ºè®°å½•å‘˜å’Œæ€»ç»“è€…ã€‚è¯·ä»”ç»†é˜…è¯»æä¾›çš„å¯¹è¯å†å²ï¼Œæç‚¼å‡ºæ ¸å¿ƒè®®é¢˜ã€å„æ–¹è§‚ç‚¹ã€è¾¾æˆçš„å…±è¯†ä»¥åŠä»»ä½•æ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚æœ€ç»ˆå¾—å‡ºä¸€ä¸ªæ¸…æ™°çš„ç»“è®ºã€‚"
        )
        
        # æ„é€ è¾“å…¥
        # å†å²å·²ç»åœ¨ self.history ä¸­
        user_msg = TextMessage(content=instruction, source="user")
        messages = self.history + [user_msg]
        
        try:
            response = await agent.on_messages(messages, cancellation_token=None)
            content = response.chat_message.content
            return {"sender": "æ€»ç»“åŠ©æ‰‹", "content": content}
        except Exception as e:
            logger.error(f"æ€»ç»“å¤±è´¥: {e}")
            return {"sender": "ç³»ç»Ÿ", "content": f"æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}"}
