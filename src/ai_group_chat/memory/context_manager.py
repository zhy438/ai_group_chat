"""
ä¸Šä¸‹æ–‡ç®¡ç†å™¨

æ ¸å¿ƒå…¥å£ï¼šæ£€æµ‹ Token é˜ˆå€¼ã€åè°ƒè°ƒç”¨åˆ†ç±»å™¨ã€è¯„åˆ†å™¨ã€åŽ‹ç¼©å™¨
"""

import tiktoken
from typing import List, Optional
from loguru import logger

from ..models import Message
from .classifier import MessageClassifier
from .value_scorer import ValueScorer
from .compressor import ContextCompressor


class ContextManager:
    """
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    è´Ÿè´£ï¼š
    1. è®¡ç®—å½“å‰ä¸Šä¸‹æ–‡çš„ Token æ•°é‡
    2. åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘åŽ‹ç¼©
    3. åè°ƒè°ƒç”¨åˆ†ç±»ã€è¯„åˆ†ã€åŽ‹ç¼©æµç¨‹
    """
    
    # é»˜è®¤é…ç½®
    DEFAULT_MODEL = "gpt-4"  # ç”¨äºŽ token è®¡ç®—çš„æ¨¡åž‹
    DEFAULT_MAX_TOKENS = 128000  # é»˜è®¤æœ€å¤§ token æ•°
    DEFAULT_THRESHOLD_RATIO = 0.8  # è§¦å‘åŽ‹ç¼©çš„é˜ˆå€¼ï¼ˆ80%ï¼‰
    
    def __init__(self,
                 model: str = DEFAULT_MODEL,
                 max_tokens: int = DEFAULT_MAX_TOKENS,
                 threshold_ratio: float = DEFAULT_THRESHOLD_RATIO):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            model: ç”¨äºŽ token è®¡ç®—çš„æ¨¡åž‹åç§°
            max_tokens: æ¨¡åž‹çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            threshold_ratio: è§¦å‘åŽ‹ç¼©çš„é˜ˆå€¼æ¯”ä¾‹
        """
        self.model = model
        self.max_tokens = max_tokens
        self.threshold_ratio = threshold_ratio
        self.threshold_tokens = int(max_tokens * threshold_ratio)
        
        # åˆå§‹åŒ– tiktoken ç¼–ç å™¨
        try:
            self.encoder = tiktoken.encoding_for_model(model)
        except KeyError:
            # å¦‚æžœæ¨¡åž‹ä¸æ”¯æŒï¼Œä½¿ç”¨ cl100k_baseï¼ˆGPT-4 ä½¿ç”¨çš„ç¼–ç ï¼‰
            self.encoder = tiktoken.get_encoding("cl100k_base")
        
        # åˆå§‹åŒ–å­ç»„ä»¶
        self.classifier = MessageClassifier()
        self.scorer = ValueScorer()
        self.compressor = ContextCompressor()
    
    def set_max_tokens(self, max_tokens: int) -> None:
        """
        åŠ¨æ€è®¾ç½®æœ€å¤§ token æ•°
        
        ç”¨äºŽæ ¹æ®ç¾¤èŠä¸­æ¨¡åž‹çš„æœ€å°ä¸Šä¸‹æ–‡çª—å£è°ƒæ•´
        
        Args:
            max_tokens: æ–°çš„æœ€å¤§ token æ•°
        """
        if max_tokens != self.max_tokens:
            old_max = self.max_tokens
            self.max_tokens = max_tokens
            self.threshold_tokens = int(max_tokens * self.threshold_ratio)
            logger.debug(f"ðŸ“ ä¸Šä¸‹æ–‡çª—å£è°ƒæ•´: {old_max} â†’ {max_tokens} tokens")
    
    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡"""
        return len(self.encoder.encode(text))
    
    def count_messages_tokens(self, messages: List[Message]) -> int:
        """
        è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€» token æ•°
        
        æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªä¼°ç®—å€¼ï¼Œå®žé™… API è°ƒç”¨æ—¶è¿˜ä¼šæœ‰é¢å¤–çš„æ ¼å¼åŒ–å¼€é”€
        """
        total = 0
        for msg in messages:
            # æ¶ˆæ¯å†…å®¹
            total += self.count_tokens(msg.content)
            # å‘é€è€…åç§°ï¼ˆçº¦ 4 tokens çš„å¼€é”€ï¼‰
            if msg.sender_name:
                total += self.count_tokens(msg.sender_name) + 4
        
        # æ·»åŠ ä¸€äº›é¢å¤–çš„æ ¼å¼åŒ–å¼€é”€ä¼°ç®—
        total += len(messages) * 4  # æ¯æ¡æ¶ˆæ¯çº¦ 4 tokens çš„æ ¼å¼å¼€é”€
        
        return total
    
    def should_compress(self, messages: List[Message]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘åŽ‹ç¼©
        
        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æ˜¯å¦éœ€è¦åŽ‹ç¼©
        """
        current_tokens = self.count_messages_tokens(messages)
        should = current_tokens >= self.threshold_tokens
        
        if should:
            logger.warning(
                f"âš ï¸ Token è¶…è¿‡é˜ˆå€¼: {current_tokens}/{self.max_tokens} "
                f"({current_tokens/self.max_tokens*100:.1f}%) >= {self.threshold_ratio*100:.0f}%"
            )
        
        return should
    
    def process(self, messages: List[Message], 
                force: bool = False) -> List[Message]:
        """
        å¤„ç†æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŽ‹ç¼©
        2. æ¶ˆæ¯åˆ†ç±»
        3. ä»·å€¼è¯„åˆ†
        4. æ‰§è¡ŒåŽ‹ç¼©
        
        Args:
            messages: åŽŸå§‹æ¶ˆæ¯åˆ—è¡¨
            force: æ˜¯å¦å¼ºåˆ¶æ‰§è¡ŒåŽ‹ç¼©ï¼ˆå¿½ç•¥é˜ˆå€¼æ£€æŸ¥ï¼‰
            
        Returns:
            å¤„ç†åŽçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½è¢«åŽ‹ç¼©ï¼‰
        """
        if not messages:
            return messages
        
        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŽ‹ç¼©
        if not force and not self.should_compress(messages):
            return messages
        
        logger.info(f"ðŸ”„ å¼€å§‹ä¸Šä¸‹æ–‡ä¼˜åŒ–æµç¨‹ï¼Œå½“å‰æ¶ˆæ¯æ•°: {len(messages)}")
        
        # 2. æ¶ˆæ¯åˆ†ç±»
        self.classifier.update_message_types(messages)
        
        # 3. ä»·å€¼è¯„åˆ†
        self.scorer.score_messages(messages)
        
        # 4. æ‰§è¡ŒåŽ‹ç¼©
        compressed_messages = self.compressor.compress(messages)
        
        # ç»Ÿè®¡åŽ‹ç¼©æ•ˆæžœ
        original_tokens = self.count_messages_tokens(messages)
        compressed_tokens = self.count_messages_tokens(compressed_messages)
        saved_tokens = original_tokens - compressed_tokens
        saved_ratio = saved_tokens / original_tokens * 100 if original_tokens > 0 else 0
        
        logger.info(
            f"âœ¨ åŽ‹ç¼©å®Œæˆ: {original_tokens} â†’ {compressed_tokens} tokens "
            f"(èŠ‚çœ {saved_tokens} tokens, {saved_ratio:.1f}%)"
        )
        
        return compressed_messages
    
    async def process_async(self, messages: List[Message], 
                            force: bool = False) -> List[Message]:
        """
        å¼‚æ­¥å¤„ç†æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¸é˜»å¡žä¸»çº¿ç¨‹ï¼‰
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŽ‹ç¼©
        2. æ¶ˆæ¯åˆ†ç±»ï¼ˆå¼‚æ­¥ LLMï¼‰
        3. ä»·å€¼è¯„åˆ†
        4. æ‰§è¡ŒåŽ‹ç¼©ï¼ˆå¼‚æ­¥ LLM æ‘˜è¦ï¼‰
        
        Args:
            messages: åŽŸå§‹æ¶ˆæ¯åˆ—è¡¨
            force: æ˜¯å¦å¼ºåˆ¶æ‰§è¡ŒåŽ‹ç¼©ï¼ˆå¿½ç•¥é˜ˆå€¼æ£€æŸ¥ï¼‰
            
        Returns:
            å¤„ç†åŽçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½è¢«åŽ‹ç¼©ï¼‰
        """
        if not messages:
            return messages
        
        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŽ‹ç¼©
        if not force and not self.should_compress(messages):
            return messages
        
        logger.info(f"ðŸ”„ å¼€å§‹å¼‚æ­¥ä¸Šä¸‹æ–‡ä¼˜åŒ–æµç¨‹ï¼Œå½“å‰æ¶ˆæ¯æ•°: {len(messages)}")
        
        # 2. æ¶ˆæ¯åˆ†ç±»ï¼ˆå¼‚æ­¥ï¼‰
        await self.classifier.update_message_types_async(messages)
        
        # 3. ä»·å€¼è¯„åˆ†ï¼ˆCPU æ“ä½œï¼Œæ— éœ€å¼‚æ­¥ï¼‰
        self.scorer.score_messages(messages)
        
        # 4. æ‰§è¡ŒåŽ‹ç¼©ï¼ˆå¼‚æ­¥ï¼‰
        compressed_messages = await self.compressor.compress_async(messages)
        
        # ç»Ÿè®¡åŽ‹ç¼©æ•ˆæžœ
        original_tokens = self.count_messages_tokens(messages)
        compressed_tokens = self.count_messages_tokens(compressed_messages)
        saved_tokens = original_tokens - compressed_tokens
        saved_ratio = saved_tokens / original_tokens * 100 if original_tokens > 0 else 0
        
        logger.info(
            f"âœ¨ å¼‚æ­¥åŽ‹ç¼©å®Œæˆ: {original_tokens} â†’ {compressed_tokens} tokens "
            f"(èŠ‚çœ {saved_tokens} tokens, {saved_ratio:.1f}%)"
        )
        
        return compressed_messages
    
    def get_stats(self, messages: List[Message]) -> dict:
        """
        èŽ·å–å½“å‰ä¸Šä¸‹æ–‡çš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        current_tokens = self.count_messages_tokens(messages)
        return {
            "message_count": len(messages),
            "current_tokens": current_tokens,
            "max_tokens": self.max_tokens,
            "threshold_tokens": self.threshold_tokens,
            "usage_ratio": current_tokens / self.max_tokens,
            "needs_compression": current_tokens >= self.threshold_tokens,
        }
