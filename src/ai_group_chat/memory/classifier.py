"""
æ¶ˆæ¯åˆ†ç±»å™¨

ä½¿ç”¨ LLM å¯¹æ¶ˆæ¯è¿›è¡Œæ™ºèƒ½åˆ†ç±»ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†å’Œé‡è¯•æœºåˆ¶
"""

import asyncio
import json
import re
from typing import List, Optional
from loguru import logger

from ..models import Message, MessageRole, MessageType
from ..llm.client import llm_client


# åˆ†ç±»æç¤ºè¯
CLASSIFY_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ†ç±»ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹å¯¹è¯æ¶ˆæ¯è¿›è¡Œåˆ†ç±»ï¼Œç”¨äºä¸Šä¸‹æ–‡å‹ç¼©å†³ç­–ã€‚

æ¶ˆæ¯ç±»å‹å®šä¹‰ï¼š
- user: ç”¨æˆ·å‘é€çš„æ¶ˆæ¯ï¼ˆæœ€é‡è¦ï¼Œå¿…é¡»ä¿ç•™ï¼‰
- status: å…³é”®çŠ¶æ€æ¶ˆæ¯ï¼ˆä»»åŠ¡å®Œæˆã€å†³ç­–ç¡®å®šã€æœ€ç»ˆç»“è®ºç­‰é‡Œç¨‹ç¢‘èŠ‚ç‚¹ï¼‰
- reasoning: æ¨ç†è¿‡ç¨‹æ¶ˆæ¯ï¼ˆæ€è€ƒåˆ†æã€æ–¹æ¡ˆæ¯”è¾ƒã€æƒè¡¡è®¨è®ºç­‰ä¸­é—´è¿‡ç¨‹ï¼‰
- failure: å¤±è´¥è®°å½•æ¶ˆæ¯ï¼ˆé”™è¯¯æŠ¥å‘Šã€å¤±è´¥åŸå› ã€é—®é¢˜è¯Šæ–­ç­‰éœ€è¦è®°ä½çš„æ•™è®­ï¼‰
- normal: æ™®é€šæ¶ˆæ¯ï¼ˆæœªæ˜ç¡®å±äºä»¥ä¸Šç±»å‹çš„ä¸€èˆ¬å¯¹è¯ï¼‰

åˆ†ç±»ä¾æ®ï¼š
1. userç±»å‹ï¼šæ¶ˆæ¯æ¥è‡ª"ç”¨æˆ·"æˆ–"User"
2. statusç±»å‹ï¼šåŒ…å«"å®Œæˆ"ã€"æˆåŠŸ"ã€"ç¡®å®š"ã€"ç»“è®º"ã€"æœ€ç»ˆ"ç­‰ç¡®å®šæ€§è¯æ±‡
3. reasoningç±»å‹ï¼šåŒ…å«"è€ƒè™‘"ã€"åˆ†æ"ã€"å¯èƒ½"ã€"å¦‚æœ"ã€"æ–¹æ¡ˆ"ç­‰æ¨ç†è¯æ±‡
4. failureç±»å‹ï¼šåŒ…å«"å¤±è´¥"ã€"é”™è¯¯"ã€"é—®é¢˜"ã€"æ— æ³•"ã€"bug"ç­‰å¤±è´¥è¯æ±‡
5. normalç±»å‹ï¼šä¸æ˜ç¡®å±äºä»¥ä¸Šç±»å‹çš„æ¶ˆæ¯

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""

CLASSIFY_USER_PROMPT = """è¯·å¯¹ä»¥ä¸‹æ¶ˆæ¯è¿›è¡Œåˆ†ç±»ã€‚

æ¶ˆæ¯åˆ—è¡¨ï¼š
{messages}

è¯·è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€æ¡æ¶ˆæ¯çš„åˆ†ç±»ç»“æœï¼š
[{{"index": 0, "type": "ç±»å‹"}}, {{"index": 1, "type": "ç±»å‹"}}, ...]

æ³¨æ„ï¼štype åªèƒ½æ˜¯ user/status/reasoning/failure/normal ä¹‹ä¸€ã€‚"""


class MessageClassifier:
    """
    æ¶ˆæ¯åˆ†ç±»å™¨
    
    ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†ç±»ï¼Œå¤±è´¥æ—¶é™çº§åˆ°è§„åˆ™åŒ¹é…
    """
    
    MAX_RETRIES = 3
    RETRY_DELAY = 1
    BATCH_SIZE = 20  # æ¯æ‰¹å¤„ç†çš„æ¶ˆæ¯æ•°é‡
    
    # è§„åˆ™åŒ¹é…çš„å…³é”®è¯ï¼ˆç”¨äºé™çº§ï¼‰
    STATUS_KEYWORDS = [
        "å®Œæˆ", "æˆåŠŸ", "å·²ç»", "ç¡®å®š", "å†³å®š", "æœ€ç»ˆ",
        "ç»“è®º", "æ€»ç»“", "é‡‡ç”¨", "é€‰æ‹©", "ç¡®è®¤",
        "done", "completed", "success", "decided", "conclusion"
    ]
    
    REASONING_KEYWORDS = [
        "è€ƒè™‘", "åˆ†æ", "æ¯”è¾ƒ", "æƒè¡¡", "æ€è€ƒ", "è¯„ä¼°",
        "æ–¹æ¡ˆ", "é€‰é¡¹", "å¯èƒ½", "æˆ–è€…", "å¦‚æœ",
        "think", "consider", "analyze", "compare", "option", "maybe"
    ]
    
    FAILURE_KEYWORDS = [
        "å¤±è´¥", "é”™è¯¯", "é—®é¢˜", "æ— æ³•", "ä¸èƒ½", "æŠ¥é”™",
        "å¼‚å¸¸", "bug", "error", "failed", "issue", "cannot"
    ]
    
    def __init__(self, model: str = "gpt-4o-mini"):
        self.model = model
        self.client = llm_client
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç”¨äºé™çº§ï¼‰
        self._status_pattern = re.compile(
            '|'.join(self.STATUS_KEYWORDS), re.IGNORECASE
        )
        self._reasoning_pattern = re.compile(
            '|'.join(self.REASONING_KEYWORDS), re.IGNORECASE
        )
        self._failure_pattern = re.compile(
            '|'.join(self.FAILURE_KEYWORDS), re.IGNORECASE
        )
    
    async def classify_batch_async(self, messages: List[Message]) -> List[MessageType]:
        """
        ä½¿ç”¨ LLM æ‰¹é‡åˆ†ç±»æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æ¶ˆæ¯ç±»å‹åˆ—è¡¨ï¼ˆä¸è¾“å…¥é¡ºåºå¯¹åº”ï¼‰
        """
        if not messages:
            return []
        
        # æ„å»ºæ¶ˆæ¯æè¿°
        msg_descriptions = []
        for i, msg in enumerate(messages):
            sender = msg.sender_name or ("ç”¨æˆ·" if msg.role == MessageRole.USER else "AI")
            msg_descriptions.append(f"[{i}] [{sender}]: {msg.content}")
        
        messages_text = "\n".join(msg_descriptions)
        user_prompt = CLASSIFY_USER_PROMPT.format(messages=messages_text)
        
        # å¸¦é‡è¯•çš„ LLM è°ƒç”¨
        last_error = None
        for attempt in range(1, self.MAX_RETRIES + 1):
            try:
                response = await self.client.chat(
                    model=self.model,
                    messages=[{"role": "user", "content": user_prompt}],
                    system_prompt=CLASSIFY_SYSTEM_PROMPT,
                    temperature=0.1,  # ä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
                    max_tokens=1000,
                )
                
                # è§£æ JSON å“åº”
                types = self._parse_response(response, len(messages))
                
                if types:
                    logger.info(f"âœ… LLM åˆ†ç±»æˆåŠŸï¼ˆç¬¬ {attempt} æ¬¡å°è¯•ï¼‰ï¼Œåˆ†ç±»äº† {len(messages)} æ¡æ¶ˆæ¯")
                    return types
                else:
                    raise ValueError("è§£æåˆ†ç±»ç»“æœå¤±è´¥")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ LLM åˆ†ç±»å¤±è´¥ï¼ˆç¬¬ {attempt}/{self.MAX_RETRIES} æ¬¡ï¼‰: {e}")
                
                if attempt < self.MAX_RETRIES:
                    await asyncio.sleep(self.RETRY_DELAY)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™åŒ¹é…
        logger.warning(f"âš ï¸ LLM åˆ†ç±»å½»åº•å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™åŒ¹é…: {last_error}")
        return [self._classify_by_rules(msg) for msg in messages]
    
    def _parse_response(self, response: str, expected_count: int) -> Optional[List[MessageType]]:
        """è§£æ LLM å“åº”çš„ JSON"""
        try:
            # å°è¯•æå– JSON æ•°ç»„
            # æœ‰æ—¶ LLM ä¼šåœ¨ JSON å‰ååŠ å…¶ä»–æ–‡å­—
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if not json_match:
                return None
            
            data = json.loads(json_match.group())
            
            if not isinstance(data, list):
                return None
            
            # æ„å»ºç±»å‹æ˜ å°„
            type_map = {}
            for item in data:
                if isinstance(item, dict) and "index" in item and "type" in item:
                    idx = item["index"]
                    type_str = item["type"].lower()
                    
                    # æ˜ å°„åˆ° MessageType
                    if type_str == "user":
                        type_map[idx] = MessageType.USER
                    elif type_str == "status":
                        type_map[idx] = MessageType.STATUS
                    elif type_str == "reasoning":
                        type_map[idx] = MessageType.REASONING
                    elif type_str == "failure":
                        type_map[idx] = MessageType.FAILURE
                    else:
                        type_map[idx] = MessageType.NORMAL
            
            # æŒ‰é¡ºåºæ„å»ºç»“æœåˆ—è¡¨
            result = []
            for i in range(expected_count):
                result.append(type_map.get(i, MessageType.NORMAL))
            
            return result
            
        except (json.JSONDecodeError, KeyError, TypeError) as e:
            logger.error(f"è§£æåˆ†ç±»å“åº”å¤±è´¥: {e}")
            return None
    
    def _classify_by_rules(self, message: Message) -> MessageType:
        """è§„åˆ™åŒ¹é…åˆ†ç±»ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        if message.role == MessageRole.USER:
            return MessageType.USER
        
        content = message.content
        
        failure_matches = len(self._failure_pattern.findall(content))
        status_matches = len(self._status_pattern.findall(content))
        reasoning_matches = len(self._reasoning_pattern.findall(content))
        
        if failure_matches >= 2:
            return MessageType.FAILURE
        if status_matches >= 2:
            return MessageType.STATUS
        if reasoning_matches >= 3:
            return MessageType.REASONING
        
        return MessageType.NORMAL
    
    def classify(self, message: Message) -> MessageType:
        """
        åŒæ­¥åˆ†ç±»å•æ¡æ¶ˆæ¯ï¼ˆä½¿ç”¨è§„åˆ™åŒ¹é…ï¼Œé¿å…å•æ¡è°ƒç”¨ LLMï¼‰
        """
        return self._classify_by_rules(message)
    
    def classify_batch(self, messages: List[Message]) -> List[MessageType]:
        """
        åŒæ­¥æ‰¹é‡åˆ†ç±»æ¶ˆæ¯
        
        å°è¯•ä½¿ç”¨ LLMï¼Œå¤±è´¥åˆ™é™çº§åˆ°è§„åˆ™åŒ¹é…
        """
        if not messages:
            return []
        
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self.classify_batch_async(messages))
                    return future.result(timeout=60)
            else:
                return loop.run_until_complete(self.classify_batch_async(messages))
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ†ç±»å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™åŒ¹é…: {e}")
            return [self._classify_by_rules(msg) for msg in messages]
    
    def update_message_types(self, messages: List[Message]) -> List[Message]:
        """
        æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ä¸­æ¯æ¡æ¶ˆæ¯çš„ message_type å­—æ®µ
        
        ä½¿ç”¨ LLM æ‰¹é‡åˆ†ç±»ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        """
        if not messages:
            return messages
        
        types = self.classify_batch(messages)
        
        for msg, msg_type in zip(messages, types):
            msg.message_type = msg_type
        
        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for t in types:
            type_counts[t.value] = type_counts.get(t.value, 0) + 1
        logger.info(f"ğŸ“Š åˆ†ç±»ç»“æœ: {type_counts}")
        
        return messages
    
    async def update_message_types_async(self, messages: List[Message]) -> List[Message]:
        """
        å¼‚æ­¥æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ä¸­æ¯æ¡æ¶ˆæ¯çš„ message_type å­—æ®µ
        
        ä½¿ç”¨ LLM æ‰¹é‡åˆ†ç±»ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰
        """
        if not messages:
            return messages
        
        types = await self.classify_batch_async(messages)
        
        for msg, msg_type in zip(messages, types):
            msg.message_type = msg_type
        
        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for t in types:
            type_counts[t.value] = type_counts.get(t.value, 0) + 1
        logger.info(f"ğŸ“Š åˆ†ç±»ç»“æœ: {type_counts}")
        
        return messages
